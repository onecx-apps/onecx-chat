# Default values for onecx-ai-svc.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/onecx-apps/onecx-ai-svc
#  repository: 728986473007.dkr.ecr.us-east-1.amazonaws.com/onecx/onecx-ai-svc
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: "main"
  


imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""


# Define environment variables
env:
  - name: CLOUD_PROVIDER
    value: "aws"
  - name: QDRANT_URL
    value: "qdrant"
  - name: QDRANT_PORT
    value: "6333"
  - name: QDRANT_COLLECTION_NAME
    value: "ollama"    
  - name: OLLAMA_URL
    value: "ollama"
  - name: OLLAMA_PORT
    value: "80"
  - name: OLLAMA_MODEL
#    value: "llama2"
#    value: "emgerman_mistral_leo"
#    value: "mixtral_8x7b"
    value: "leo_hessianai"
  - name: OLLAMA_MODEL_VERSION
#    value: "13b-chat-q4_0"
    value: "latest"

  - name: Q_A_SYSTEM_MESSAGE
    value: "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n
    If you don't know the answer to a question, please don't share false information.\n 
    Only use the information you get from the retrieved context. If you can not find any information in the context, than say 'No information provided'.\n
    Use three sentences maximum and keep the answer concise.\n
    If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.\n
    Please answer in the same language as the user asked the question.\n"

  ### template of ollama is used if False otherwise it will use template of the svc 
  - name: OLLAMA_RAW_MODE
    value: "True"
  - name: COHERE_API_KEY
    value: "y4CX8otjHckAKf6AXGFCz3YyQFI6TWaNNg1eGw5y"
  - name: ACTIVATE_RERANKER
    value: "True"
  - name: EMBEDDING_MODEL
#    value: "all-MiniLM-L6-v2"
#    value: "embed-multilingual-v3.0"
    value: "intfloat/multilingual-e5-base"
  - name: AMOUNT_SIMILARITY_SEARCH_RESULTS
    value: "20"
  - name: DOCUMENTS_BUCKET
    value: "onecx-chat-documents"

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: LoadBalancer
  ports:
    - name: http
      port: 80
      targetPort: 80
      protocol: TCP

livenessProbe:
  initialDelaySeconds: 5
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 10
  successThreshold: 1

readinessProbe:
  initialDelaySeconds: 20
  periodSeconds: 5
  timeoutSeconds: 1
  failureThreshold: 6
  successThreshold: 1


ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

hooks:
  postInstall:
    enabled: true
  hostedZoneId: "Z04691503R1QKP3NPCK74"
  recordSetName: "ai-svc.one-cx.org"
  namespace: "genai"
  releaseName: "onecx-ai-svc"
  region: "us-east-1"
  loadBalancerHostedZoneId: "Z35SXDOTRQ7X7K"


resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
   limits:
     nvidia.com/gpu: 5
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}
